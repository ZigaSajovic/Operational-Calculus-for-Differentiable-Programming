\input{../latexCommon/preamble.tex}
\title{Operational calculus on Programming Spaces}
\author{\v{Z}iga Sajovic, Martin Vuk}

\begin{document}
\maketitle

\section{Introduction}


With names as Differentiable programming, and Software 2.0. becoming attached to deep learning, it is showing itself to be more than a black-box machine learning algorithm, but a new programming paradigm.

Usual treaties of programs, with precise denotational semantics only talks about programs, without the ability to manipulate their properties. This has partially been addressed by algebraic data types employed by functional programming, where a connection has been shown between grammars and semirings; for an example of how this algebraic view is used to show an isomorphism between data types, see \cite{7Trees}. Yet the lack of inverses (hence the semiring structure) we remain limited in the algebraic manipulations we are allowed to employ \cite{complexCat}.

Due to it (Deep Learning) being rooted in tensor algebra, its paradigm has the ability to address such issues, \emph{because unlike von Neumann languages, the language of ordinary algebra is suitable both for stating its laws and for transforming
an equation into its solution, all within the language} \cite{backus}.

With most of the work in the field being empirical, the field lacks a formal theory that would ease theoretical investigations.

With the right formalism in-place, deep learning becomes a solution to these problems.

analysis and programming

\printbibliography

\end{document}