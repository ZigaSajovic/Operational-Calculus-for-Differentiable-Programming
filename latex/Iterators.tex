 \subsection{Iterators and Iterating Velocity}
 

  Iterator is a functional, composing a program $p\in\dP$ with itself. For ease of expression, we denote the $n$-th iterate of a program $p\in\dP:\VV\to \VV$, as $p^n$, as it is possible to view iteration as compositional exponentiation. In this view, one may seek to explore the relation between the value of the $n$-th iterate and $n$. With a form which expresses the iterate as a function of $n$, one could inquire its rate of change in relation to it and even investigate fractional iterations
\footnote{Similar to fractional factorials of the \emph{gamma} function, or fractional powers of other operators.}.
  
Let $\mathcal{I}_p$ be the monoid generated by $p\in\dP:V\to V$ under composition $\circ$
  
  \begin{equation}\label{eq:iter_def}
  \mathcal{I}_p=\{p^n:\VV\to \VV;\quad p(a)=a\},
  \end{equation}
 with some fixed point $a\in \VV$. We than turn towards analysing the structure of \eqref{eq:iter_def} in relation to $n$, the number of iterations.

Let $h$ be the map defined with the eigen equation  
\begin{equation}\label{eq:kh}
  h(p(x))=\lambda h(x)
  \end{equation}
   \begin{equation}
   h(a)=0
   \end{equation}
It is clear that the action of $h$ on $p$ is such, 
  \begin{equation}
  h(p^n(x))=\lambda^nh(x)
  \end{equation}
that in the image of $h$, iterations of $p$ become multiplication with the eigen value $\lambda$. We can express the eigen value by differentiating $\eqref{eq:kh}$ at the fixed point $a$,
$$\D h(p(a))\D p(a)=\lambda\D h(a)\implies\D p(a)=\lambda.$$

The derived equips us to inquire about the rate of change of the values of a program $p$ in relation to $n$, the number of iterations. Lets define iterating velocity as
  \begin{equation}
  v(p^n)=\D_np^n(x)
  \end{equation}
Of course
  \begin{equation}
  v(p^n(a))=0
  \end{equation}
the iterating velocity at the fixed point $a$ is constantly zero, which is deduced from the $\eqref{eq:kh}$ and reassures our intuition. Next, we introduce a change of variables $\lambda= e^\nu$ for mathematical convenience and proceed towards computing the iterating velocity.
  $$\D_nh(p^n)=\D_n(e^{\nu n}h(x))$$
  $$\implies$$
  $$\D h(p^n(x))\D_np^n(x)=\nu e^{\nu n}h(x) \land e^{\nu n}h(x)=h(p^n(x))$$
  $$\implies$$
  \begin{equation}\label{eq:iter_vel}
  v=\nu(\D h)^{-1}h
  \end{equation}
The iterating velocity
\footnote{Higher derivatives can be derived by induction.}
\eqref{eq:iter_vel} can be used to study the importance of future iterations for the accumulating result, and aid with decisions on early stopping. Furthermore, the above indicates a subclass of programs for which the Halting problem can be analysed through the study of convergence and fixed points.

The computation of the eigen map $h$ \eqref{eq:kh} was solved by Bridges \cite{bridges2016solution} for any $p$ with a power series representation. This result is extended to tensor series by the isomorphism to their quotient. Hence, as we can expand any $p\in\dP$ into a tensor series by the use of the operator $e^\D$, the result also holds for any $p\in\dP$ by Theorem $\ref{izr:e^d}$. 


\subsection{ReduceSum in the Language of Operational Calculus}

As a demonstration of the algebraic power over analytic conclusions inherent to our model, we examine the functional \emph{ReduceSum}, and derive its explicit form as a function of $n$, the number of its iterations, or upper bound, with special interest in the rate of change of the functional in relation to $n$; i.e. iterating velocity and its higher order counter parts. 

Let $\mathcal{S}^n$ denote the operator, that performs a linear shift of a program $p$ in the direction $\vv$, from its initial point $\vv_0$.
   \begin{equation}\label{eq:sn_oper}
   \mathcal{S}^n:\dP(\vv_0)\to \dP(\vv_0+n\vv),
   \end{equation}  
and let $\mathcal{S}$, for a specific $\vv_0, \vv\in \VV$, denote the group generated by \eqref{eq:sn_oper} under composition and addition. By Theorem $\ref{izr:e^d}$ we have
  \begin{equation}\label{eq:sn=ed}
e^{h\D}\dP(\vv_0)(\vv)=\dP(\vv_0+h\vv)\implies \mathcal{S}^h=e^{h\D},
  \end{equation}
and thus clearly $\mathcal{S}^n\cdot\mathcal{S}^m=\mathcal{S}^{n+m}$ and $(\mathcal{S}^n+\mathcal{S}^m)(\dP)=\mathcal{S}^n(\dP)+\mathcal{S}^m(\dP)$, which we use to define the $n$-th reduction as
$$\mathcal{R}_+^n=(1+\mathcal{S}+\mathcal{S}^2+\cdots+\mathcal{S}^n),$$
that results in
   $$\mathcal{R}^n_+(\dP)(\vv)=\sum\limits_{h=0}^{n}\dP(\vv_0+h\vv)$$
upon application.

With this we turn towards computing with operators alone to harness the algebraic power of our framework. We write
$$(1+\mathcal{S}+\mathcal{S}^2+\cdots+\mathcal{S}^n)=1+\mathcal{S}(1+\mathcal{S}+\mathcal{S}^2+\cdots+\mathcal{S}^{n-1})$$
   $$\implies$$
   $$1-\mathcal{S}^n=(1-S)\mathcal{R}^{n-1}_+$$
   $$\implies$$
  \begin{equation}
\mathcal{R}^{n-1}_+=(1-\mathcal{S}^n)(\frac{1}{1-\mathcal{S}})
  \end{equation}
Recognizing that $(1-\mathcal{S}^n)$ represents the action of evaluating a program at endpoints and subtracting and taking Theorem \ref{izr:e^d} into account we write
  \begin{equation}\label{eq:Rn+Basic}
    \mathcal{R}^{n-1}_+=\D^{-1}(\frac{\D}{1-e^\D})\Bigg\vert_{\vv_0}^{n\vv}
  \end{equation}
assuming invertibility at the endpoints. The parenthesised expression, $\frac{\D}{1-e^\D}$, is an algebraic encoding of a higher-order program, which is be expanded into explicit form inside the tensor series algebra of the memory space $\VV\otimes \T(\VV^*)$. Doing so, we recognize
\begin{equation}
    	\frac{h\D}{1-e^{h\D}}=\sum\limits_{n=0}^{\infty}B_n\frac{(h\D)^n}{n!}
    \end{equation}
$B_n$ to be the $n$-th Bernoulli number. Thus the higher order program
$$\mathcal{R}^{n-1}_+\in \VV\otimes \T(\VV^*):\VV\to\VV$$
is expressed as 
    \begin{equation}\label{eq:Rn+}
      \mathcal{R}^{n-1}_+=\Bigg\{B_0\D^{-1}+\sum\limits_{i=1}^{\infty}B_i\frac{\D^{i-1}}{i!}\Bigg\}\Bigg\vert_{\vv_0}^{n\vv}.
    \end{equation}
Upon applying it to a program at a particular point $\vv\in \VV$ this becomes
\begin{equation}\label{eq:Rn+P}
  \mathcal{R}^{n-1}_+\dP(\vv)=\Bigg\{B_0\D^{-1}\dP(t)+\sum\limits_{i=1}^{\infty}B_i\frac{\D^{i-1}\dP(t)}{i!}\Bigg\}\Bigg\vert_{\vv_0}^{n\vv} \Big(\vv\Big),
    \end{equation}
where the evaluation at $\vv\in \VV$, as by \eqref{eq:polynomial_tensor}, performs the needed translation, as the image of the operator $\mathcal{R}^{n-1}_+$ is an element of the tensor series algebra of the memory space $\VV\otimes \T(\VV^*)$.
Note that the number of iterations, $n$, is the only remaining free variable, as desired.
\begin{remark}
  When $p\in\dP$ is an univariate mapping, the expression \eqref{eq:Rn+P} recovers the Euler-Maclaurin integral formula \cite{apostol1999elementary}, which is demonstrated by applying the operator \eqref{eq:Rn+} to the function $x^m$
$$\mathcal{R}^n_+(x^m)=\frac{1}{m+1}\sum_{k=0}^m{m+1\choose k}B_kn^{m+1-k},$$
and producing the closed form solution.
\end{remark}
Furthermore, due to the operational algebra of higher order programs established by our model, we can compute the operator of iterating velocity (and higher order change) of the $n$-th iterate by differentiating the operator $\mathcal{R}^{n-1}_+$ itself. Reverting to the form \eqref{eq:Rn+Basic} and substituting \eqref{eq:sn=ed}, we have
\begin{equation}
  \frac{d^k}{dn^k}\mathcal{R}^{n-1}_+=\frac{d^k}{dn^k}\Big((1-e^{n\D})(\frac{1}{1-e^\D})\Big)=\mathcal{S}^n(\frac{\D^n}{1-e^\D}),
   \end{equation}
where commutativity of shifting and differentiating was used. Noting that $\mathcal{S}^n$ simply shifts the operand in the direction of $\vv$ by a factor of $n$, the explicit form 
\begin{equation}
        \frac{d^k}{dn^k}\mathcal{R}^{n-1}_+\dP\vert_{n=N}(\vv)=\Big(\sum\limits_{i=0}^{\infty}B_i\frac{\D^{N-1+i}\dP(N\vv)}{i!}\Big)\Big(\vv\Big)
        \end{equation}
where the evaluation at $\vv\in \VV$ once again performs the needed translation.

